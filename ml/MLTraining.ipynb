{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from config import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, RandomizedSearchCV, GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import shap\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.feature_selection import RFE\n",
    "import ast\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakenewsnet = pd.read_csv('../data/wf/FakeNewsNet_wf.csv')\n",
    "isot = pd.read_csv('../data/wf/FakeNewsISOT_wf.csv')\n",
    "fakenewskaggle = pd.read_csv('../data/wf/FakeNewsKaggle_wf.csv')\n",
    "buzfeed_political = pd.read_csv('../data/wf/FakeNewsBuzfeedPolitical_wf.csv')\n",
    "celebrity = pd.read_csv('../data/wf/FakeNewsCelebrity_wf.csv')\n",
    "fakenewsamt = pd.read_csv('../data/wf/FakeNewsAMT_wf.csv')\n",
    "fn_randompolitical = pd.read_csv('../data/wf/FakeNewsRandomPolitical_wf.csv')\n",
    "fn_politfalse = pd.read_csv('../data/wf/FakeNewsPolitFalse_wf.csv')\n",
    "fn_satirical = pd.read_csv('../data/wf/FakeNewsSatirical_wf.csv')\n",
    "fn_mcintire = pd.read_csv('../data/wf/FakeNewsMcintire_wf.csv')\n",
    "\n",
    "datasets = {\n",
    "    'FakeNewsNet' : fakenewsnet,\n",
    "    'ISOT' : isot,\n",
    "    'FakeNewsKaggle' : fakenewskaggle,\n",
    "    'FakeNewsAMT' : fakenewsamt,\n",
    "    'FakeNewsRandomPolitical' : fn_randompolitical,\n",
    "    'FakeNewsCelebrity' : celebrity,\n",
    "    'FakeNewsBuzfeedPolitical' : buzfeed_political,\n",
    "    'FakeNewsPolitFalse' : fn_politfalse,\n",
    "    'FakeNewsSatirical' : fn_satirical,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe with some statistics about all datasets (number of words of the 'text' column, etc.), and the populate it with information about each dataset\n",
    "def get_dataset_stats(dataset, name):\n",
    "    dataset_stats = pd.DataFrame()\n",
    "    dataset_stats['dataset'] = [name]\n",
    "    dataset_stats['num_rows'] = [dataset.shape[0]]\n",
    "    dataset_stats['num_cols'] = [dataset.shape[1]]\n",
    "    dataset_stats['avg_word_len'] = [dataset['text'].str.split().str.len().mean()]\n",
    "    dataset_stats['avg_char_len'] = [dataset['text'].str.len().mean()]\n",
    "    dataset_stats['num_unique_words'] = [dataset['text'].str.split().apply(lambda x: len(set(x))).sum()]\n",
    "    return dataset_stats\n",
    "\n",
    "dataset_stats = pd.DataFrame()\n",
    "for dataset_name, dataset in datasets.items():\n",
    "    dataset_stats = pd.concat([dataset_stats, get_dataset_stats(dataset, dataset_name)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name, dataset in datasets.items():\n",
    "    print(dataset_name)\n",
    "    print(dataset['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sets = {\n",
    "    'Moral' : MORAL_FEATURES,\n",
    "    'ReadabilityGrades' : READABILITY_GRADE_FEATURES,\n",
    "    'ReadabilitySentenceInfo' : READABILITY_SENTENCEINFO_FEATURES,\n",
    "    'ReadabilitySentenceBegininng' : READABILITY_SENTENCEBEGINNING_FEATURES,\n",
    "    'ReadabilityWordUsage' : READABILITY_WORDUSAGE_FEATURES,\n",
    "    'AllReadability' : READABILITY_GRADE_FEATURES + READABILITY_SENTENCEINFO_FEATURES + READABILITY_SENTENCEBEGINNING_FEATURES + READABILITY_WORDUSAGE_FEATURES,\n",
    "    'Sentiment' : SENTIMENT_FEATURES,\n",
    "    'Subjectivity' : ['subjectivity'],\n",
    "    'Emotion' : EMOTION_FEATURES,\n",
    "    'LIWCLinguistic' : LIWC_LINGUISTIC_FEATURES,\n",
    "    'LIWCAffectiveProcesses' : LIWC_AFFECTIVEPROCESSES_FEATURES,\n",
    "    'LIWCSocialProcesses' : LIWC_SOCIALPROCESSES_FEATURES,\n",
    "    'LIWCCognitiveProcesses' : LIWC_COGNITIVEPROCESSES_FEATURES,\n",
    "    'LIWCPerceptualProcesses' : LIWC_PERCEPTUALPROCESSES_FEATURES,\n",
    "    'LIWCBiologicalProcesses' : LIWC_BIOLOGICALPROCESSES_FEATURES,\n",
    "    'LIWCDrives' : LIWC_DRIVES_FEATURES,\n",
    "    'LIWCTimeOrientation' : LIWC_TIMEORIENTATION_FEATURES,\n",
    "    'LIWCRelativity' : LIWC_RELATIVITY_FEATURES,\n",
    "    'LIWCPersonalConcerns' : LIWC_PERSONALCONCERNS_FEATURES,\n",
    "    'LIWCInformalLanguage' : LIWC_INFORMALLANGUAGE_FEATURES,\n",
    "    'AllLIWC' : LIWC_LINGUISTIC_FEATURES + LIWC_AFFECTIVEPROCESSES_FEATURES + LIWC_SOCIALPROCESSES_FEATURES + LIWC_COGNITIVEPROCESSES_FEATURES + LIWC_PERCEPTUALPROCESSES_FEATURES + LIWC_BIOLOGICALPROCESSES_FEATURES \n",
    "        + LIWC_DRIVES_FEATURES + LIWC_TIMEORIENTATION_FEATURES + LIWC_RELATIVITY_FEATURES + LIWC_PERSONALCONCERNS_FEATURES + LIWC_INFORMALLANGUAGE_FEATURES,\n",
    "    'All' : MORAL_FEATURES + READABILITY_GRADE_FEATURES + READABILITY_SENTENCEINFO_FEATURES + READABILITY_SENTENCEBEGINNING_FEATURES + READABILITY_WORDUSAGE_FEATURES + SENTIMENT_FEATURES + LIWC_LINGUISTIC_FEATURES + LIWC_AFFECTIVEPROCESSES_FEATURES + LIWC_SOCIALPROCESSES_FEATURES + LIWC_COGNITIVEPROCESSES_FEATURES + LIWC_PERCEPTUALPROCESSES_FEATURES + LIWC_BIOLOGICALPROCESSES_FEATURES \n",
    "        + LIWC_DRIVES_FEATURES + LIWC_TIMEORIENTATION_FEATURES + LIWC_RELATIVITY_FEATURES + LIWC_PERSONALCONCERNS_FEATURES + LIWC_INFORMALLANGUAGE_FEATURES + ['subjectivity'] + EMOTION_FEATURES\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_memory_usage(df):   \n",
    "    start_memory = df.memory_usage().sum() / 1024**2\n",
    "    print(f\"Memory usage of dataframe is {start_memory} MB\")\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != 'object':\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            \n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "                    \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    pass\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "    \n",
    "    end_memory = df.memory_usage().sum() / 1024**2\n",
    "    print(f\"Memory usage of dataframe after reduction {end_memory} MB\")\n",
    "    print(f\"Reduced by {100 * (start_memory - end_memory) / start_memory} % \")\n",
    "    return df\n",
    "\n",
    "def get_collinear_features(x, threshold):\n",
    "    '''\n",
    "    Objective:\n",
    "        Remove collinear features in a dataframe with a correlation coefficient\n",
    "        greater than the threshold. Removing collinear features can help a model \n",
    "        to generalize and improves the interpretability of the model.\n",
    "\n",
    "    Inputs: \n",
    "        x: features dataframe\n",
    "        threshold: features with correlations greater than this value are removed\n",
    "\n",
    "    Output: \n",
    "        dataframe that contains only the non-highly-collinear features\n",
    "    '''\n",
    "\n",
    "    # Calculate the correlation matrix\n",
    "    corr_matrix = x.corr()\n",
    "    iters = range(len(corr_matrix.columns) - 1)\n",
    "    drop_cols = []\n",
    "\n",
    "    # Iterate through the correlation matrix and compare correlations\n",
    "    for i in iters:\n",
    "        for j in range(i+1):\n",
    "            item = corr_matrix.iloc[j:(j+1), (i+1):(i+2)]\n",
    "            col = item.columns\n",
    "            row = item.index\n",
    "            val = abs(item.values)\n",
    "\n",
    "            # If correlation exceeds the threshold\n",
    "            if val >= threshold:\n",
    "                # Print the correlated features and the correlation value\n",
    "                #print(col.values[0], \"|\", row.values[0], \"|\", round(val[0][0], 2))\n",
    "                drop_cols.append(col.values[0])\n",
    "\n",
    "    # Drop one of each pair of correlated columns\n",
    "    drops = set(drop_cols)\n",
    "    # x = x.drop(columns=drops)\n",
    "    return drops\n",
    "\n",
    "def get_low_score_features(df, feature_names):\n",
    "    np.random.seed(24091993)\n",
    "    df['random_var_1'] = np.random.random(size=len(df))\n",
    "    df['random_var_2'] = np.random.random(size=len(df))\n",
    "    \n",
    "    X = df[feature_names]\n",
    "    y = df['label']\n",
    "\n",
    "    ig = mutual_info_regression(X, y)\n",
    "\n",
    "    # Create a dictionary of feature importance scores\n",
    "    feature_scores = {}\n",
    "    for i in range(len(feature_names)):\n",
    "        feature_scores[feature_names[i]] = ig[i]\n",
    "    # Add the random variables to the feature scores dictionary\n",
    "    feature_scores['random_var_1'] = ig[-2]  # Assuming ig has the importance scores for the added random variables\n",
    "    feature_scores['random_var_2'] = ig[-1]\n",
    "\n",
    "    # Sort the features by importance score in descending order\n",
    "    sorted_features = sorted(feature_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the importance score of 'random_var_1'\n",
    "    random_var_1_score = feature_scores['random_var_1']\n",
    "    random_var_2_score = feature_scores['random_var_2']\n",
    "\n",
    "    # Get the features whose importance score is lower than the importance score of 'random_var_1'\n",
    "    less_important_features = [feature for feature, score in sorted_features if (score < random_var_1_score or score < random_var_2_score) ]\n",
    "\n",
    "    return set(less_important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = []\n",
    "for dataset_name, dataset in datasets.items():\n",
    "    print('---Dataset {dataset_name}---'.format(dataset_name=dataset_name))\n",
    "    df = dataset[feature_sets['All'] + ['label']]\n",
    "    df = df.loc[:,~df.columns.duplicated()].copy()\n",
    "    datasets[dataset_name] = reduce_memory_usage(df)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de nombres de las features\n",
    "features = feature_sets['All']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definir el umbral de correlación alta\n",
    "correlation_threshold = 0.9\n",
    "\n",
    "# Función para encontrar las features altamente correlacionadas en un dataset\n",
    "def get_highly_correlated_features(df, threshold):\n",
    "    corr_matrix = df.corr().abs()\n",
    "    upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    highly_correlated = [column for column in upper_triangle.columns if any(upper_triangle[column] > threshold)]\n",
    "    return highly_correlated\n",
    "\n",
    "# Encontrar las features altamente correlacionadas en todos los datasets\n",
    "all_highly_correlated_features = []\n",
    "for dataset_name, dataset in datasets.items():\n",
    "    correlated_features = get_highly_correlated_features(dataset[features], correlation_threshold)\n",
    "    all_highly_correlated_features.append(set(correlated_features))\n",
    "\n",
    "# Encontrar la intersección de features altamente correlacionadas en todos los datasets\n",
    "common_highly_correlated_features = set.intersection(*all_highly_correlated_features)\n",
    "\n",
    "print(\"Features altamente correlacionadas en todos los datasets:\")\n",
    "print(common_highly_correlated_features)\n",
    "\n",
    "# Eliminar las features altamente correlacionadas de los datasets\n",
    "datasets = {name: df.drop(columns=common_highly_correlated_features) for name, df in datasets.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove common_highly_correlated_features from features\n",
    "features = [feature for feature in features if feature not in common_highly_correlated_features]\n",
    "\n",
    "# Crear un DataFrame vacío para almacenar los resultados\n",
    "results_fa = pd.DataFrame(columns=features, index=datasets.keys())\n",
    "\n",
    "# Iterar sobre cada dataset\n",
    "for dataset_name, df in datasets.items():\n",
    "    print('---- Dataset %s' % dataset_name)\n",
    "\n",
    "    df = df.copy()\n",
    "    \n",
    "    # scale dataset\n",
    "    scaler = StandardScaler()\n",
    "    df[features] = scaler.fit_transform(df[features])\n",
    "\n",
    "\n",
    "    # Separar las noticias falsas y legítimas\n",
    "    df_false = df[df['label'] == 1]\n",
    "    df_legit = df[df['label'] == 0]\n",
    "    \n",
    "    # Calcular la diferencia de medias para cada feature\n",
    "    for feature in features:\n",
    "        mean_false = df_false[feature].mean()\n",
    "        mean_legit = df_legit[feature].mean()\n",
    "        difference = mean_false - mean_legit\n",
    "        \n",
    "        # Almacenar la diferencia en el DataFrame de resultados\n",
    "        results_fa.at[dataset_name, feature] = difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asumiendo que ya tienes el DataFrame results_df con las diferencias normalizadas\n",
    "\n",
    "# Crear una lista para almacenar las top 20 features de cada dataset\n",
    "top_features_per_dataset_list = []\n",
    "\n",
    "# Iterar sobre cada dataset para encontrar las 20 features con mayor diferencia positiva\n",
    "for dataset_name in results_fa.index:\n",
    "    # Ordenar las features por la diferencia positiva\n",
    "    top_features = results_fa.loc[dataset_name].sort_values(ascending=False).head(20).index\n",
    "    # Añadir las features a la lista\n",
    "    for feature in top_features:\n",
    "        top_features_per_dataset_list.append({'Feature': feature, 'Dataset': dataset_name})\n",
    "\n",
    "# Convertir la lista a un DataFrame\n",
    "top_features_per_dataset = pd.DataFrame(top_features_per_dataset_list)\n",
    "\n",
    "# Contar cuántas veces aparece cada feature en los top 20 de todos los datasets\n",
    "feature_counts = top_features_per_dataset['Feature'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_counts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asumiendo que ya tienes el DataFrame results_df con las diferencias normalizadas\n",
    "\n",
    "# Crear una lista para almacenar las top 20 features con mayor diferencia negativa de cada dataset\n",
    "top_negative_features_per_dataset_list = []\n",
    "\n",
    "# Iterar sobre cada dataset para encontrar las 20 features con mayor diferencia negativa\n",
    "for dataset_name in results_fa.index:\n",
    "    # Ordenar las features por la diferencia negativa\n",
    "    top_negative_features = results_fa.loc[dataset_name].sort_values(ascending=True).head(20).index\n",
    "    # Añadir las features a la lista\n",
    "    for feature in top_negative_features:\n",
    "        top_negative_features_per_dataset_list.append({'Feature': feature, 'Dataset': dataset_name})\n",
    "\n",
    "# Convertir la lista a un DataFrame\n",
    "top_negative_features_per_dataset = pd.DataFrame(top_negative_features_per_dataset_list)\n",
    "\n",
    "# Contar cuántas veces aparece cada feature en los top 20 de todos los datasets\n",
    "negative_feature_counts = top_negative_features_per_dataset['Feature'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar los resultados\n",
    "negative_feature_counts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asumiendo que ya tienes el DataFrame results_df con las diferencias normalizadas\n",
    "\n",
    "# Función para obtener las 20 features con menor diferencia en cada dataset\n",
    "def get_top_20_smallest_diff_features(dataframe):\n",
    "    top_20_features = {}\n",
    "    for dataset in dataframe.index:\n",
    "        smallest_diff_features = dataframe.loc[dataset].abs().sort_values().head(20).index\n",
    "        top_20_features[dataset] = smallest_diff_features\n",
    "    return top_20_features\n",
    "\n",
    "# Obtener las 20 features con menor diferencia en cada dataset\n",
    "top_20_features = get_top_20_smallest_diff_features(results_fa)\n",
    "\n",
    "# Contar la frecuencia de cada feature en los top 20 de todos los datasets\n",
    "feature_counts = pd.Series(np.concatenate(list(top_20_features.values()))).value_counts()\n",
    "\n",
    "# Si deseas ver el resultado de una manera más estructurada\n",
    "top_20_features_df = pd.DataFrame.from_dict(top_20_features, orient='index').T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_counts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asumiendo que ya tienes el DataFrame results_fa con las diferencias normalizadas\n",
    "\n",
    "# Calcular la media de la influencia de cada feature en cada dataset\n",
    "mean_influences = results_fa.mean(axis=0)\n",
    "\n",
    "# Identificar las 10 features con la mayor influencia positiva\n",
    "top_10_positive_features = mean_influences.sort_values(ascending=False).head(10).index\n",
    "\n",
    "# Identificar las 10 features con la mayor influencia negativa\n",
    "top_10_negative_features = mean_influences.sort_values(ascending=True).head(10).index\n",
    "\n",
    "# Identificar las 20 features con la mayor influencia positiva\n",
    "top_20_positive_features = mean_influences.sort_values(ascending=False).head(40).index\n",
    "\n",
    "# Identificar las 20 features con la mayor influencia negativa\n",
    "top_20_negative_features = mean_influences.sort_values(ascending=True).head(40).index\n",
    "\n",
    "# Filtrar el DataFrame results_fa para estas features\n",
    "top_positive_df = results_fa[top_10_positive_features]\n",
    "top_negative_df = results_fa[top_10_negative_features]\n",
    "\n",
    "# Convertir todas las columnas a tipo numérico por si acaso\n",
    "top_positive_df = top_positive_df.apply(pd.to_numeric)\n",
    "top_negative_df = top_negative_df.apply(pd.to_numeric)\n",
    "\n",
    "# Función para anotar los outliers con el nombre del dataset\n",
    "def annotate_outliers(ax, data, dataset_names):\n",
    "    for i, feature in enumerate(data.columns):\n",
    "        y = data[feature]\n",
    "        x = np.full(len(y), i + 1)\n",
    "        Q1 = np.percentile(y, 25)\n",
    "        Q3 = np.percentile(y, 75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        outliers = y[(y < lower_bound) | (y > upper_bound)]\n",
    "        for outlier_idx in outliers.index:\n",
    "            xi = i + 1\n",
    "            yi = outliers[outlier_idx]\n",
    "            dataset_name = outlier_idx\n",
    "            ax.text(xi, yi, dataset_name, ha='right', fontsize=12)\n",
    "\n",
    "# Aumentar el tamaño de las fuentes para todos los textos\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "# Crear un diagrama de cajas para las 10 features con la mayor influencia positiva\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xticks(fontsize=16)\n",
    "ax = sns.boxplot(data=top_positive_df, palette=\"Blues\")\n",
    "plt.title('Top 10 Features with Highest Positive Influence', fontsize=22)\n",
    "plt.ylabel('Normalized Influence', fontsize=18)\n",
    "plt.xticks(rotation=45, fontsize=16)\n",
    "annotate_outliers(ax, top_positive_df, results_fa.index)\n",
    "plt.show()\n",
    "\n",
    "# Crear un diagrama de cajas para las 10 features con la mayor influencia negativa\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xticks(fontsize=16)\n",
    "ax = sns.boxplot(data=top_negative_df, palette=\"Reds\")\n",
    "plt.title('Top 10 Features with Highest Negative Influence', fontsize=22)\n",
    "plt.ylabel('Normalized Influence', fontsize=18)\n",
    "plt.xticks(rotation=45, fontsize=16)\n",
    "annotate_outliers(ax, top_negative_df, results_fa.index)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_positive_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_negative_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_global_features = top_10_positive_features.tolist() + top_10_negative_features.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_40_global_features = top_20_positive_features.tolist() + top_20_negative_features.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_40_global_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_global_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis by algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [\n",
    "    'DecisionTree',\n",
    "    'LinearSVC' ,\n",
    "    'LogisticRegression',\n",
    "    'RandomForest',\n",
    "    'XGBoost',\n",
    "    'CatBoost',\n",
    "]\n",
    "\n",
    "def get_algorithm(name):\n",
    "    if name == 'XGBoost' : \n",
    "        return XGBClassifier(n_jobs=-1)\n",
    "    elif name == 'CatBoost' :\n",
    "        return CatBoostClassifier(verbose=False)\n",
    "    elif name == 'DecisionTree' :\n",
    "        return DecisionTreeClassifier(class_weight='balanced')\n",
    "    elif name == 'SVC' :\n",
    "        return SVC(class_weight='balanced')\n",
    "    elif name == 'LinearSVC':\n",
    "        return LinearSVC(class_weight='balanced')\n",
    "    elif name == 'RandomForest' :\n",
    "        return RandomForestClassifier(class_weight='balanced', n_jobs=-1)\n",
    "    elif name == 'LogisticRegression' :\n",
    "        return LogisticRegression(class_weight='balanced', n_jobs=-1, max_iter=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(240993)\n",
    "\n",
    "# create dataframe for results\n",
    "results_df = pd.DataFrame(columns=['dataset', 'algorithm', 'fit_time', 'accuracy_mean', 'accuracy_std', 'precision_weighted_mean', 'precision_weighted_std', 'recall_weighted_mean', 'recall_weighted_std', 'f1_weighted_mean', 'f1_weighted_std', 'precision_macro_mean', 'precision_macro_std', 'recall_macro_mean', 'recall_macro_std', 'f1_macro_mean', 'f1_macro_std', 'precision_micro_mean', 'precision_micro_std', 'recall_micro_mean', 'recall_micro_std', 'f1_micro_mean', 'f1_micro_std'])\n",
    "for dataset_name, dataset in datasets.items():\n",
    "    print('---Dataset {dataset_name}---'.format(dataset_name=dataset_name))\n",
    "    \n",
    "    X = dataset[features].fillna(0)\n",
    "    y = dataset['label']\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    for algorithm_name in algorithms:\n",
    "        print('---Algorithm {algorithms_name}---'.format(algorithms_name=algorithm_name))\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=24091993)\n",
    "        scores = cross_validate(get_algorithm(algorithm_name), X, y, cv=cv, scoring=['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted', 'precision_micro', 'recall_micro', 'f1_micro', 'precision_macro', 'recall_macro', 'f1_macro'], n_jobs=-1)\n",
    "\n",
    "        # add results to dataframe using concat method\n",
    "        results_df = pd.concat([results_df, pd.DataFrame({\n",
    "            'dataset' : [dataset_name],\n",
    "            'algorithm' : [algorithm_name],\n",
    "            'fit_time' : np.mean(scores['fit_time']),\n",
    "            'score_time' : np.mean(scores['score_time']),\n",
    "            'accuracy_mean' : np.mean(scores['test_accuracy']),\n",
    "            'accuracy_std' : np.std(scores['test_accuracy']),\n",
    "            'precision_weighted_mean' : np.mean(scores['test_precision_weighted']),\n",
    "            'precision_weighted_std' : np.std(scores['test_precision_weighted']),\n",
    "            'recall_weighted_mean' : np.mean(scores['test_recall_weighted']),\n",
    "            'recall_weighted_std' : np.std(scores['test_recall_weighted']),\n",
    "            'f1_weighted_mean' : np.mean(scores['test_f1_weighted']),\n",
    "            'f1_weighted_std' : np.std(scores['test_f1_weighted']),\n",
    "            'precision_macro_mean' : np.mean(scores['test_precision_macro']),\n",
    "            'precision_macro_std' : np.std(scores['test_precision_macro']),\n",
    "            'recall_macro_mean' : np.mean(scores['test_recall_macro']),\n",
    "            'recall_macro_std' : np.std(scores['test_recall_macro']),\n",
    "            'f1_macro_mean' : np.mean(scores['test_f1_macro']),\n",
    "            'f1_macro_std' : np.std(scores['test_f1_macro']),\n",
    "            'precision_micro_mean' : np.mean(scores['test_precision_micro']),\n",
    "            'precision_micro_std' : np.std(scores['test_precision_micro']),\n",
    "            'recall_micro_mean' : np.mean(scores['test_recall_micro']),\n",
    "            'recall_micro_std' : np.std(scores['test_recall_micro']),\n",
    "            'f1_micro_mean' : np.mean(scores['test_f1_micro']),\n",
    "            'f1_micro_std' : np.std(scores['test_f1_micro'])\n",
    "        })], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.groupby(['algorithm']).mean(numeric_only=True)[['accuracy_mean', 'accuracy_std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.groupby(['dataset']).mean(numeric_only=True)[['f1_weighted_mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[results_df['algorithm']=='LogisticRegression'][['dataset', 'precision_weighted_mean', 'recall_weighted_mean', 'f1_weighted_mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_40_global_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_40_global_features[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_40_global_features[40:45]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms with differen number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(240993)\n",
    "\n",
    "# create dataframe for results\n",
    "results_df_mf = pd.DataFrame(columns=['dataset', 'num_features', 'algorithm', 'fit_time', 'accuracy_mean', 'accuracy_std', 'precision_weighted_mean', 'precision_weighted_std', 'recall_weighted_mean', 'recall_weighted_std', 'f1_weighted_mean', 'f1_weighted_std', 'precision_macro_mean', 'precision_macro_std', 'recall_macro_mean', 'recall_macro_std', 'f1_macro_mean', 'f1_macro_std', 'precision_micro_mean', 'precision_micro_std', 'recall_micro_mean', 'recall_micro_std', 'f1_micro_mean', 'f1_micro_std'])\n",
    "for dataset_name, dataset in datasets.items():\n",
    "    print('---Dataset {dataset_name}---'.format(dataset_name=dataset_name))\n",
    "    possible_num_features = [3, 5, 8, 10, 15, 20, 25, 30, 35, 40]\n",
    "    for num_features in possible_num_features:\n",
    "        print('---Number of features {num_features}---'.format(num_features=num_features))\n",
    "        \n",
    "        # select the top num_features from top_20_global_features head and the top num_features from the tail\n",
    "        top_num_features_head = top_40_global_features[:num_features]\n",
    "        top_num_features_tail = top_40_global_features[max(possible_num_features):(max(possible_num_features)+num_features)]\n",
    "        top_num_features = top_num_features_head + top_num_features_tail\n",
    "\n",
    "        X = dataset[top_num_features]\n",
    "        y = dataset['label']\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "\n",
    "        for algorithm_name in algorithms:\n",
    "            print('---Algorithm {algorithms_name}---'.format(algorithms_name=algorithm_name))\n",
    "            cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=24091993)\n",
    "            scores = cross_validate(get_algorithm(algorithm_name), X, y, cv=cv, scoring=['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted', 'precision_micro', 'recall_micro', 'f1_micro', 'precision_macro', 'recall_macro', 'f1_macro'], n_jobs=-1)\n",
    "\n",
    "            # add results to dataframe using concat method\n",
    "            results_df_mf = pd.concat([results_df_mf, pd.DataFrame({\n",
    "                'dataset' : [dataset_name],\n",
    "                'num_features' : [num_features],\n",
    "                'algorithm' : [algorithm_name],\n",
    "                'fit_time' : np.mean(scores['fit_time']),\n",
    "                'accuracy_mean' : np.mean(scores['test_accuracy']),\n",
    "                'accuracy_std' : np.std(scores['test_accuracy']),\n",
    "                'precision_weighted_mean' : np.mean(scores['test_precision_weighted']),\n",
    "                'precision_weighted_std' : np.std(scores['test_precision_weighted']),\n",
    "                'recall_weighted_mean' : np.mean(scores['test_recall_weighted']),\n",
    "                'recall_weighted_std' : np.std(scores['test_recall_weighted']),\n",
    "                'f1_weighted_mean' : np.mean(scores['test_f1_weighted']),\n",
    "                'f1_weighted_std' : np.std(scores['test_f1_weighted']),\n",
    "                'precision_macro_mean' : np.mean(scores['test_precision_macro']),\n",
    "                'precision_macro_std' : np.std(scores['test_precision_macro']),\n",
    "                'recall_macro_mean' : np.mean(scores['test_recall_macro']),\n",
    "                'recall_macro_std' : np.std(scores['test_recall_macro']),\n",
    "                'f1_macro_mean' : np.mean(scores['test_f1_macro']),\n",
    "                'f1_macro_std' : np.std(scores['test_f1_macro']),\n",
    "                'precision_micro_mean' : np.mean(scores['test_precision_micro']),\n",
    "                'precision_micro_std' : np.std(scores['test_precision_micro']),\n",
    "                'recall_micro_mean' : np.mean(scores['test_recall_micro']),\n",
    "                'recall_micro_std' : np.std(scores['test_recall_micro']),\n",
    "                'f1_micro_mean' : np.mean(scores['test_f1_micro']),\n",
    "                'f1_micro_std' : np.std(scores['test_f1_micro'])\n",
    "            })], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_mf.groupby(['num_features', 'algorithm'])[['fit_time', 'f1_weighted_mean', 'f1_weighted_std']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_mf.groupby(['num_features', 'dataset'])[['fit_time', 'f1_weighted_mean', 'f1_weighted_std']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_mf[(results_df_mf['num_features']==20) & (results_df_mf['algorithm']=='XGBoost')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_mf[(results_df_mf['num_features']==20) & (results_df_mf['algorithm']=='XGBoost')].groupby(['dataset'])[['fit_time', 'f1_weighted_mean', 'f1_weighted_std']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_mf[(results_df_mf['algorithm']=='XGBoost')].groupby(['num_features', 'dataset'])[['fit_time', 'f1_weighted_mean', 'f1_weighted_std']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_results = results_df_mf.groupby(['num_features', 'dataset'])[['f1_weighted_mean']].mean().reset_index()\n",
    "\n",
    "# Hacer el plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Obtener el número único de datasets\n",
    "datasets = grouped_results['dataset'].unique()\n",
    "\n",
    "# Plotear cada dataset\n",
    "for dataset in datasets:\n",
    "    subset = grouped_results[grouped_results['dataset'] == dataset]\n",
    "    plt.plot(subset['num_features']*2, subset['f1_weighted_mean'], marker='o', label=dataset)\n",
    "\n",
    "# Configurar el gráfico\n",
    "plt.title('F1 Weighted Mean vs Number of Features')\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('F1 Weighted Mean')\n",
    "plt.legend(title='Dataset')\n",
    "plt.grid(True)\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Agrupar por 'num_features' y 'dataset', y calcular la media\n",
    "grouped_results = results_df_mf.groupby(['num_features', 'dataset'])[['f1_weighted_mean']].mean().reset_index()\n",
    "\n",
    "# Calcular la media global para cada 'num_features' (independientemente del dataset)\n",
    "mean_overall = grouped_results.groupby('num_features')['f1_weighted_mean'].mean().reset_index()\n",
    "\n",
    "# Filtrar para que solo incluya num_features * 2 <= 40\n",
    "grouped_results = grouped_results[grouped_results['num_features'] * 2 <= 50]\n",
    "mean_overall = mean_overall[mean_overall['num_features'] * 2 <= 50]\n",
    "\n",
    "# Hacer el plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Obtener el número único de datasets\n",
    "datasets = grouped_results['dataset'].unique()\n",
    "\n",
    "# Plotear cada dataset\n",
    "for dataset in datasets:\n",
    "    subset = grouped_results[grouped_results['dataset'] == dataset]\n",
    "    plt.plot(subset['num_features']*2, subset['f1_weighted_mean'], marker='o', label=dataset)\n",
    "\n",
    "# Plotear la media global\n",
    "plt.plot(mean_overall['num_features']*2, mean_overall['f1_weighted_mean'], marker='x', linestyle='--', color='black', label='Average')\n",
    "\n",
    "# Configurar el gráfico\n",
    "plt.title('F1 Weighted Mean vs Number of Features', fontsize=16)  # Título más grande\n",
    "plt.xlabel('Number of Features', fontsize=14)  # Texto del eje x más grande\n",
    "plt.ylabel('F1 Weighted Mean', fontsize=14)  # Texto del eje y más grande\n",
    "plt.legend(title='Dataset', fontsize=12, title_fontsize=14)  # Leyenda con textos más grandes\n",
    "plt.grid(True)\n",
    "\n",
    "# Aumentar el tamaño de las etiquetas de los ejes\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_mf.groupby(['num_features'])[['fit_time']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_mf[(results_df_mf['num_features']==15)].groupby(['algorithm'])[['fit_time']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Agrupar por 'num_features' y 'dataset', y calcular la media\n",
    "grouped_results = results_df_mf.groupby(['num_features', 'algorithm'])[['fit_time']].mean().reset_index()\n",
    "\n",
    "# Calcular la media global para cada 'num_features' (independientemente del dataset)\n",
    "mean_overall = grouped_results.groupby('num_features')['fit_time'].mean().reset_index()\n",
    "\n",
    "# Filtrar para que solo incluya num_features * 2 <= 40\n",
    "grouped_results = grouped_results[grouped_results['num_features'] * 2 <= 50]\n",
    "mean_overall = mean_overall[mean_overall['num_features'] * 2 <= 50]\n",
    "\n",
    "# Hacer el plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Obtener el número único de datasets\n",
    "datasets = grouped_results['algorithm'].unique()\n",
    "\n",
    "# Plotear cada dataset\n",
    "for algorithm_name in algorithms:\n",
    "    subset = grouped_results[grouped_results['algorithm'] == algorithm_name]\n",
    "    plt.plot(subset['num_features']*2, subset['fit_time'], marker='o', label=algorithm_name)\n",
    "\n",
    "# Plotear la media global\n",
    "plt.plot(mean_overall['num_features']*2, mean_overall['fit_time'], marker='x', linestyle='--', color='black', label='Average')\n",
    "\n",
    "# Configurar el gráfico\n",
    "plt.title('F1 Weighted Mean vs Number of Features', fontsize=16)  # Título más grande\n",
    "plt.xlabel('Number of Features', fontsize=14)  # Texto del eje x más grande\n",
    "plt.ylabel('F1 Weighted Mean', fontsize=14)  # Texto del eje y más grande\n",
    "plt.legend(title='Dataset', fontsize=12, title_fontsize=14)  # Leyenda con textos más grandes\n",
    "plt.grid(True)\n",
    "\n",
    "# Aumentar el tamaño de las etiquetas de los ejes\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainability for LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_global_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe for results\n",
    "results_shap = {}\n",
    "\n",
    "np.random.seed(240993)\n",
    "\n",
    "algorithm_name = 'XGBoost'\n",
    "\n",
    "for datasets_name, dataset in datasets.items():\n",
    "    print('---Dataset {datasets_name}---'.format(datasets_name=datasets_name))\n",
    "    results_shap[datasets_name] = {}\n",
    "\n",
    "    X = dataset[top_20_global_features]\n",
    "    y = dataset['label']\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    # create model\n",
    "\n",
    "    model = get_algorithm(algorithm_name)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2409199)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # print classification report\n",
    "    print(classification_report(y_test, model.predict(X_test)))\n",
    "    \n",
    "    model = get_algorithm(algorithm_name).fit(X, y)\n",
    "    \n",
    "    background_X = shap.maskers.Independent(X, max_samples=100)\n",
    "\n",
    "    # create explainer\n",
    "    explainer = shap.Explainer(model.predict, background_X)\n",
    "\n",
    "    # create shap values\n",
    "    shap_values = explainer(X)\n",
    "\n",
    "    results_shap[datasets_name]['features'] = top_20_global_features\n",
    "    results_shap[datasets_name]['shap_values'] = shap_values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_agg = results_shap['ISOT']['shap_values'].values\n",
    "\n",
    "for dataset_name in datasets.keys():\n",
    "    sv_agg = np.concatenate((sv_agg, results_shap[dataset_name]['shap_values'].values), axis=0)\n",
    "\n",
    "shap.summary_plot(sv_agg, feature_names=results_shap[dataset_name]['features'], plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
